---
title: "Final Project:  Checkpoint 3"
author: "Katherine M. Prioli"
date: "November 20, 2019"
output:
  pdf_document: default
  html_document: default
geometry: margin = 0.5in
---

## **Progress to Date**

The following progress has been made since Checkpoint 2:

* Improved mean accuracy of random forest performance from 52% to 75% via hyperparameter tuning and refinement of dataset
  * Investigated methods of variable selection for largely categorical data (e.g., PCA approaches for categorical variables) but ultimately these didn't pan out
* Began unsupervised clustering approach
* Continued to flesh out the final report with respect to the supervised learning approach, including Methods, Results, and the Limitations part of Discussion
  
## **Next Steps**

* Finish unsupervised clustering approach
* Continue working on final report
* Draft presentation slides
  
## **Challenges**

I have been unable to achieve better than 75% mean performance from the random forest.  Though 75% is a meaningful improvement above last week's 52%, it would not be acceptable in any real-world application.  It's possible that this data is not optimal for modeling via decision trees - for example, I suspect that the inclusion of a category for nonresponses in the categorical variables has introduced noise to the data; however, `randomForestClassifier()` threw an error when running with missing values, and this approach was preferable to omitting cases with missing categorical data.  Additionally, many of the variables included in the analysis are derived from questionnaires, particularly those pertaining to dietary and exercise habits.  Self-reported data can be unreliable, and this may be frustrating my classifier.  Additionally, I had planned to generate a "mean" confusion matrix aggregating all runs for this data but am omitting this objective in favor of working on the unsupervised approach.

No changes to the timeline are proposed at this point.

## **Supervised Approach:  Final Model Results**

```{python libs, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
# Importing libraries

import math
import numpy as np
import pandas as pd
# import scipy   # Do I need this?  Could use R for stats instead
# import xgboost as xgb

from sklearn import ensemble
from sklearn import tree

from sklearn.metrics import confusion_matrix

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
# from sklearn.model_selection import train_test_split   # I'm not calling this
```

```{python import_subset, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
# Note:  "initial" commented out because it won't return the true initial results since data wrangling has been refactored

# nhanes_i = r.nhanes
# nhanes_feat_i = nhanes_i.drop(["BMI_cat"], axis = 1)
# nhanes_labs_i = nhanes_i.filter(["BMI_cat"])   # .filter() works as a `keep` or dplyr::select()

nhanes_f = r.nhanes_sup_trim_dichot
nhanes_feat_f = nhanes_f.drop(["BMI_cat"], axis = 1)
nhanes_labs_f = nhanes_f.filter(["BMI_cat"])
```

```{python nxk_rkf, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
# Note:  "initial" commented out because it won't return the true initial results since data wrangling has been refactored

# rfc_i = ensemble.RandomForestClassifier(n_estimators = 100) 
# rkf_i = RepeatedKFold(n_repeats = 5, n_splits = 5)   # Reminder:  n = # repeats; k = # splits = # folds
# 
# scores_i = cross_val_score(rfc_i, nhanes_feat_i, nhanes_labs_i.values.ravel(), cv = rkf_i)   # Note:  ravel() flattens the array of labels
# scores_i = pd.DataFrame(scores_i)

rfc_f = ensemble.RandomForestClassifier(n_estimators = 200, min_samples_leaf = 25, bootstrap = False) #max_depth = 7, 
rkf_f = RepeatedKFold(n_repeats = 10, n_splits = 3)

scores_f = cross_val_score(rfc_f, nhanes_feat_f, nhanes_labs_f.values.ravel(), cv = rkf_f)
scores_f = pd.DataFrame(scores_f)
```

```{r score_rkf, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
# Note:  "initial" commented out because it won't return the true initial results since data wrangling has been refactored

# scores_init <- py$scores_i %>% 
#   unlist() %>% 
#   as_tibble() %>% 
#   rename(score = value) %>% 
#   select(score) %>% 
#   mutate(score = as.numeric(score)) %>% 
#   summarize(n_runs = n(),
#             pct_acc = paste0(round(mean(score), digits = 4) * 100, "%"),
#             sd_acc = (round(sd(score), digits = 4) * 100),
#             min_acc = paste0(round(min(score), digits = 4) * 100, "%"),
#             max_acc = paste0(round(max(score), digits = 4) * 100, "%"))
# 
# scores_init_kbl <- scores_init %>% 
#   kable(format = "markdown")
# scores_init_kbl

scores_final <- py$scores_f %>% 
  unlist() %>% 
  as_tibble() %>% 
  rename(score = value) %>% 
  select(score) %>% 
  mutate(score = as.numeric(score)) %>% 
  summarize(n_runs = n(),
            pct_acc = round(mean(score), digits = 4) * 100,
            sd_acc = (round(sd(score), digits = 4) * 100),
            min_acc = round(min(score), digits = 4) * 100,
            max_acc = round(max(score), digits = 4) * 100)

scores_final_kbl <- scores_final %>% 
  kable(format = "markdown")
scores_final_kbl
```

## **Unsupervised Approach**

Dissimilarity matrix based on Gower distance:

```{r dissim, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
dissim_mat <- daisy(nhanes_unsup[ ,2:dim(nhanes_unsup)[2]], metric = "gower")
summary(dissim_mat)
```

Dendrogram for agglomerative clustering/nesting (AGNES) using the dissimilarity matrix:

```{r agnes_dend, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}

```


Dendrogram for divisive clustering/analysis (DIANA), again using the dissimilarity matrix:

```{r diana_dend, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
diana_dend <- diana(x = (dissim_mat %>% as_matrix()), diss = TRUE, keep.diss = TRUE) %>% 
  as.dendrogram() %>% 
  ggdendrogram()
diana_dend
```
