---
title: "Final Project:  Checkpoint 2"
author: "Katherine M. Prioli"
date: "November 13, 2019"
output:
  pdf_document: default
  html_document: default
geometry: margin = 0.5in
---

## **Progress to Date**

x

Despite these challenges, there are no proposed changes to the scope or timeline.


## **Supervised Learning Approach**

```{python libs, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
# Importing libraries

import math
import numpy as np
import pandas as pd
import scipy   # Do I need this?  Could use R for stats instead
import xgboost as xgb

from sklearn import ensemble
from sklearn import tree

from sklearn.metrics import confusion_matrix

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import train_test_split
```



```{python import_subset, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
nhanes = r.nhanes
nhanes_feat = nhanes.drop(['seqn', 'BMI_cat'], axis = 1)
nhanes_labs = nhanes.filter(['BMI_cat'])   # .filter() works as a `keep` or dplyr::select()

# nhanes.head(6)   # Eyeballing to make sure it all looks good
# np.all(np.isfinite(nhanes))   # Double-checking that nothing converted to NAN or Inf

```



<!-- IGNORE THE BELOW CODE (don't think I'll need it) -->

<!-- ```{python xgboost, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6} -->
<!-- rkf = RepeatedKFold(n_splits = 5, n_repeats = 5)   # Reminder:  n = # splits = # folds; k = # repeats -->
<!-- for train_index, test_index in rkf.split(nhanes_feat): -->
<!--   rf = xgb.XGBRFClassifier().fit(nhanes_feat[train_index], nhanes_labs[test_index]) -->
<!-- ``` -->





```{python nxk_rkf, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
rfc = ensemble.RandomForestClassifier(n_estimators = 100)
rkf = RepeatedKFold(n_splits = 5, n_repeats = 5)   # Reminder:  n = # splits = # folds; k = # repeats

# Do I even need this?  I don't think so
# X_train, X_test, y_train, y_test = train_test_split(nhanes_feat, nhanes_labs, test.size = 0.3)

scores = cross_val_score(rfc, nhanes_feat, nhanes_labs.values.ravel(), cv = rkf)   # Note:  ravel() flattens the array of labels
scores = pd.DataFrame(scores)
print(scores)
```



```{r score_rkf, echo = FALSE, paged.print = FALSE, fig.width = 10, fig.height = 6}
scores <- py$scores %>% 
  unlist() %>% 
  as_tibble() %>% 
  rename(score = value) %>% 
  select(score) %>% 
  mutate(score = as.numeric(score)) %>% 
  summarize(n_runs = n(),
            pct_acc = round(mean(score), digits = 2),
            sd_acc = round(sd(score), digits = 3),
            min_acc = round(min(score), digits = 2),
            max_acc = round(max(score), digits = 2)) %>% 
  kable(format = "markdown")
scores
```


## **Heading**

